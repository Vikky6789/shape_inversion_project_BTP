{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b82a41e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-04T17:29:37.209681Z",
     "iopub.status.busy": "2026-01-04T17:29:37.209406Z",
     "iopub.status.idle": "2026-01-04T17:29:38.829086Z",
     "shell.execute_reply": "2026-01-04T17:29:38.828350Z"
    },
    "papermill": {
     "duration": 1.624219,
     "end_time": "2026-01-04T17:29:38.830437",
     "exception": false,
     "start_time": "2026-01-04T17:29:37.206218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/data-shape-inversion/data/CRN_dataset.py\n",
      "/kaggle/input/data-shape-inversion/data/synsetoffset2category.txt\n",
      "/kaggle/input/data-shape-inversion/data/ply_dataset.py\n",
      "/kaggle/input/data-shape-inversion/data/__init__.py\n",
      "/kaggle/input/data-shape-inversion/data/CRN/our_data/test_data.h5\n",
      "/kaggle/input/data-shape-inversion/data/CRN/our_data/mean_feature.h5\n",
      "/kaggle/input/data-shape-inversion/data/CRN/our_data/valid_data.h5\n",
      "/kaggle/input/data-shape-inversion/data/CRN/our_data/train_data.h5\n",
      "/kaggle/input/data-shape-inversion/data/our_data/test_data.h5\n",
      "/kaggle/input/data-shape-inversion/data/our_data/mean_feature.h5\n",
      "/kaggle/input/data-shape-inversion/data/our_data/valid_data.h5\n",
      "/kaggle/input/data-shape-inversion/data/our_data/train_data.h5\n",
      "/kaggle/input/pretrained-models-shape-inversion/pretrained_models/car.pt\n",
      "/kaggle/input/pretrained-models-shape-inversion/pretrained_models/.gitignore\n",
      "/kaggle/input/pretrained-models-shape-inversion/pretrained_models/couch.pt\n",
      "/kaggle/input/pretrained-models-shape-inversion/pretrained_models/lamp.pt\n",
      "/kaggle/input/pretrained-models-shape-inversion/pretrained_models/table.pt\n",
      "/kaggle/input/pretrained-models-shape-inversion/pretrained_models/cabinet.pt\n",
      "/kaggle/input/pretrained-models-shape-inversion/pretrained_models/watercraft.pt\n",
      "/kaggle/input/pretrained-models-shape-inversion/pretrained_models/chair.pt\n",
      "/kaggle/input/pretrained-models-shape-inversion/pretrained_models/plane.pt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f70bb845",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T17:29:38.835603Z",
     "iopub.status.busy": "2026-01-04T17:29:38.835280Z",
     "iopub.status.idle": "2026-01-04T17:31:28.713419Z",
     "shell.execute_reply": "2026-01-04T17:31:28.712523Z"
    },
    "papermill": {
     "duration": 109.882053,
     "end_time": "2026-01-04T17:31:28.714682",
     "exception": false,
     "start_time": "2026-01-04T17:29:38.832629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Reset CWD to: /kaggle/working\n",
      "‚¨áÔ∏è Cloning fresh copy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'shape_inversion_project_BTP'...\n",
      "Updating files: 100% (529/529), done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Entered Project Root: /kaggle/working/shape_inversion_project_BTP\n",
      "\n",
      "üì¶ Installing ninja...\n",
      "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 43.3/43.3 kB 1.4 MB/s eta 0:00:00\n",
      "\n",
      "[1/2] Compiling Chamfer3D backend in: /kaggle/working/shape_inversion_project_BTP/external/ChamferDistancePytorch/chamfer3D\n",
      "Processing /kaggle/working/shape_inversion_project_BTP/external/ChamferDistancePytorch/chamfer3D\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: chamfer_3D\n",
      "  Building wheel for chamfer_3D (setup.py): started\n",
      "  Building wheel for chamfer_3D (setup.py): finished with status 'done'\n",
      "  Created wheel for chamfer_3D: filename=chamfer_3D-0.0.0-cp311-cp311-linux_x86_64.whl size=2701000 sha256=58cc0b4f8c9e5b83fdbe937403f05280f8c6a3eafae659a15359d58a63688e5b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-i1vlqr_p/wheels/cd/a3/62/43f9a1e320bd0de46c387bf0ed7c3b86a12a841a5685e3f69d\n",
      "Successfully built chamfer_3D\n",
      "Installing collected packages: chamfer_3D\n",
      "Successfully installed chamfer_3D-0.0.0\n",
      "   ‚úÖ Chamfer3D Compilation Successful\n",
      "\n",
      "[2/2] Compiling EMD in: /kaggle/working/shape_inversion_project_BTP/external/emd\n",
      "Processing /kaggle/working/shape_inversion_project_BTP/external/emd\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: emd\n",
      "  Building wheel for emd (setup.py): started\n",
      "  Building wheel for emd (setup.py): finished with status 'done'\n",
      "  Created wheel for emd: filename=emd-0.0.0-cp311-cp311-linux_x86_64.whl size=2739054 sha256=469b239febca7f03c55c5b39f868c63b217313a28a1d25b5631d682dcea7cd7c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-1di3jid1/wheels/6a/28/cb/3a19229a47088919ae1f5b6e4c9c0b5145ba52ac86951e6644\n",
      "Successfully built emd\n",
      "Installing collected packages: emd\n",
      "Successfully installed emd-0.0.0\n",
      "   ‚úÖ EMD Compilation Successful\n",
      "\n",
      "‚úÖ SETUP COMPLETE.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELL 1: FINAL SETUP (Corrects Chamfer3D Path)\n",
    "# ===================================================================\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# 1. Reset to Kaggle Working Root\n",
    "os.chdir(\"/kaggle/working\")\n",
    "print(f\"üìç Reset CWD to: {os.getcwd()}\")\n",
    "\n",
    "repo_url = \"https://github.com/Vikky6789/shape_inversion_project_BTP.git\"\n",
    "repo_name = \"shape_inversion_project_BTP\"\n",
    "\n",
    "# 2. Cleanup Old Repo\n",
    "if os.path.exists(repo_name):\n",
    "    print(f\"üßπ Removing existing '{repo_name}'...\")\n",
    "    shutil.rmtree(repo_name)\n",
    "\n",
    "# 3. Clone\n",
    "print(f\"‚¨áÔ∏è Cloning fresh copy...\")\n",
    "subprocess.check_call(f\"git clone {repo_url}\", shell=True)\n",
    "\n",
    "# 4. Enter Repo\n",
    "os.chdir(repo_name)\n",
    "PROJECT_ROOT = os.getcwd()\n",
    "sys.path.append(PROJECT_ROOT) # Critical for imports later\n",
    "print(f\"üìç Entered Project Root: {PROJECT_ROOT}\")\n",
    "\n",
    "# 5. Install Dependencies\n",
    "print(\"\\nüì¶ Installing ninja...\")\n",
    "subprocess.check_call(\"pip install -q ninja plyfile\", shell=True)\n",
    "\n",
    "# 6. Compile External Modules\n",
    "\n",
    "# --- Compile Chamfer3D (The backend for ChamferDistancePytorch) ---\n",
    "# FIX: Point to the 'chamfer3D' subfolder where setup.py lives\n",
    "chamfer_src = os.path.join(PROJECT_ROOT, \"external/ChamferDistancePytorch/chamfer3D\")\n",
    "\n",
    "if os.path.exists(chamfer_src):\n",
    "    print(f\"\\n[1/2] Compiling Chamfer3D backend in: {chamfer_src}\")\n",
    "    os.chdir(chamfer_src)\n",
    "    \n",
    "    if os.path.exists(\"setup.py\"):\n",
    "        try:\n",
    "            # We use install because it registers the package globally in the env\n",
    "            subprocess.check_call(\"pip install .\", shell=True)\n",
    "            print(\"   ‚úÖ Chamfer3D Compilation Successful\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"   ‚ùå Chamfer3D Compilation FAILED. Error: {e}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå ERROR: 'setup.py' still missing in {chamfer_src}\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå ERROR: Path not found: {chamfer_src}\")\n",
    "\n",
    "# --- Compile EMD ---\n",
    "emd_path = os.path.join(PROJECT_ROOT, \"external/emd\")\n",
    "if os.path.exists(emd_path):\n",
    "    print(f\"\\n[2/2] Compiling EMD in: {emd_path}\")\n",
    "    os.chdir(emd_path)\n",
    "    if os.path.exists(\"setup.py\"):\n",
    "        try:\n",
    "            subprocess.check_call(\"pip install .\", shell=True)\n",
    "            print(\"   ‚úÖ EMD Compilation Successful\")\n",
    "        except subprocess.CalledProcessError:\n",
    "             print(\"   ‚ùå EMD Compilation FAILED.\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå ERROR: 'setup.py' missing in {emd_path}\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå ERROR: Path not found: {emd_path}\")\n",
    "\n",
    "# 7. Final Return\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(\"\\n‚úÖ SETUP COMPLETE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9994053",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T17:31:28.720829Z",
     "iopub.status.busy": "2026-01-04T17:31:28.720597Z",
     "iopub.status.idle": "2026-01-04T17:31:28.723992Z",
     "shell.execute_reply": "2026-01-04T17:31:28.723263Z"
    },
    "papermill": {
     "duration": 0.007685,
     "end_time": "2026-01-04T17:31:28.725035",
     "exception": false,
     "start_time": "2026-01-04T17:31:28.717350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Cell 2: Run the setup to compile EMD\n",
    "# # We are already inside the 'shape_inversion_project_BTP' folder from the previous cell\n",
    "\n",
    "# print(\"Starting Kaggle environment setup...\")\n",
    "# !pip install -q ninja\n",
    "\n",
    "# # Navigate, compile, and return to the root\n",
    "# %cd external/emd/\n",
    "# !python setup.py install\n",
    "# %cd /kaggle/working/shape_inversion_project_BTP/\n",
    "\n",
    "# print(\"\\nSUCCESS: Kaggle environment setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "600cefde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T17:31:28.730784Z",
     "iopub.status.busy": "2026-01-04T17:31:28.730425Z",
     "iopub.status.idle": "2026-01-04T17:31:43.520129Z",
     "shell.execute_reply": "2026-01-04T17:31:43.519249Z"
    },
    "papermill": {
     "duration": 14.793968,
     "end_time": "2026-01-04T17:31:43.521376",
     "exception": false,
     "start_time": "2026-01-04T17:31:28.727408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è Restructuring models from '/kaggle/input/pretrained-models-shape-inversion/pretrained_models' to 'checkpoints'...\n",
      "   -> Found 8 models.\n",
      "   ‚úÖ Created: checkpoints/car/checkpoint.pt\n",
      "   ‚úÖ Created: checkpoints/couch/checkpoint.pt\n",
      "   ‚úÖ Created: checkpoints/lamp/checkpoint.pt\n",
      "   ‚úÖ Created: checkpoints/table/checkpoint.pt\n",
      "   ‚úÖ Created: checkpoints/cabinet/checkpoint.pt\n",
      "   ‚úÖ Created: checkpoints/watercraft/checkpoint.pt\n",
      "   ‚úÖ Created: checkpoints/chair/checkpoint.pt\n",
      "   ‚úÖ Created: checkpoints/plane/checkpoint.pt\n",
      "\n",
      "üéâ DONE. Folder structure is now fixed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "SOURCE_DIR = \"/kaggle/input/pretrained-models-shape-inversion/pretrained_models\"\n",
    "DEST_DIR = \"checkpoints\" \n",
    "# =================================================\n",
    "\n",
    "print(f\"üõ†Ô∏è Restructuring models from '{SOURCE_DIR}' to '{DEST_DIR}'...\")\n",
    "\n",
    "# 1. ROBUST CLEANUP (Fixes the OSError)\n",
    "if os.path.exists(DEST_DIR):\n",
    "    # Check if it is a Symbolic Link\n",
    "    if os.path.islink(DEST_DIR):\n",
    "        print(f\"   üóëÔ∏è Removing existing symbolic link: {DEST_DIR}\")\n",
    "        os.unlink(DEST_DIR) # correctly removes the link\n",
    "    else:\n",
    "        print(f\"   üóëÔ∏è Removing existing directory: {DEST_DIR}\")\n",
    "        shutil.rmtree(DEST_DIR) # correctly removes a real folder\n",
    "\n",
    "# 2. Create fresh folder\n",
    "os.makedirs(DEST_DIR, exist_ok=True)\n",
    "\n",
    "# 3. Get list of all .pt files\n",
    "model_files = [f for f in os.listdir(SOURCE_DIR) if f.endswith(\".pt\")]\n",
    "print(f\"   -> Found {len(model_files)} models.\")\n",
    "\n",
    "# 4. Restructure: Copy and Rename\n",
    "for filename in model_files:\n",
    "    # Example: \"watercraft.pt\" -> class \"watercraft\"\n",
    "    class_name = filename.replace(\".pt\", \"\")\n",
    "    \n",
    "    # Create folder: checkpoints/watercraft/\n",
    "    class_folder = os.path.join(DEST_DIR, class_name)\n",
    "    os.makedirs(class_folder, exist_ok=True)\n",
    "    \n",
    "    src_path = os.path.join(SOURCE_DIR, filename)\n",
    "    # Target: checkpoints/watercraft/checkpoint.pt\n",
    "    dest_path = os.path.join(class_folder, \"checkpoint.pt\")\n",
    "    \n",
    "    shutil.copy(src_path, dest_path)\n",
    "    print(f\"   ‚úÖ Created: {dest_path}\")\n",
    "\n",
    "print(\"\\nüéâ DONE. Folder structure is now fixed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfd88c41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T17:31:43.528218Z",
     "iopub.status.busy": "2026-01-04T17:31:43.527771Z",
     "iopub.status.idle": "2026-01-04T17:35:00.216156Z",
     "shell.execute_reply": "2026-01-04T17:35:00.215278Z"
    },
    "papermill": {
     "duration": 196.693049,
     "end_time": "2026-01-04T17:35:00.217429",
     "exception": false,
     "start_time": "2026-01-04T17:31:43.524380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Root: /kaggle/working/shape_inversion_project_BTP\n",
      "\n",
      "üöÄ Running watercraft with CD...\n",
      "[INFO] Using device: cuda\n",
      "Current Generator architecture:\n",
      "Number of GCN layers: 7\n",
      "Degrees: [1, 2, 2, 2, 2, 2, 64]\n",
      "Features: [96, 256, 256, 256, 128, 128, 128, 3]\n",
      "\n",
      "Layer 0 parameters:\n",
      "  W_branch: torch.Size([1, 96, 96])\n",
      "  bias: torch.Size([1, 1, 256])\n",
      "  W_root.0.weight: torch.Size([256, 96])\n",
      "  W_loop.0.weight: torch.Size([960, 96])\n",
      "  W_loop.1.weight: torch.Size([256, 960])\n",
      "\n",
      "Layer 1 parameters:\n",
      "  W_branch: torch.Size([1, 256, 512])\n",
      "  bias: torch.Size([1, 2, 256])\n",
      "  W_root.0.weight: torch.Size([256, 96])\n",
      "  W_root.1.weight: torch.Size([256, 256])\n",
      "  W_loop.0.weight: torch.Size([2560, 256])\n",
      "  W_loop.1.weight: torch.Size([256, 2560])\n",
      "\n",
      "Layer 2 parameters:\n",
      "  W_branch: torch.Size([2, 256, 512])\n",
      "  bias: torch.Size([1, 2, 256])\n",
      "  W_root.0.weight: torch.Size([256, 96])\n",
      "  W_root.1.weight: torch.Size([256, 256])\n",
      "  W_root.2.weight: torch.Size([256, 256])\n",
      "  W_loop.0.weight: torch.Size([2560, 256])\n",
      "  W_loop.1.weight: torch.Size([256, 2560])\n",
      "\n",
      "Layer 3 parameters:\n",
      "  W_branch: torch.Size([4, 256, 512])\n",
      "  bias: torch.Size([1, 2, 128])\n",
      "  W_root.0.weight: torch.Size([128, 96])\n",
      "  W_root.1.weight: torch.Size([128, 256])\n",
      "  W_root.2.weight: torch.Size([128, 256])\n",
      "  W_root.3.weight: torch.Size([128, 256])\n",
      "  W_loop.0.weight: torch.Size([2560, 256])\n",
      "  W_loop.1.weight: torch.Size([128, 2560])\n",
      "\n",
      "Layer 4 parameters:\n",
      "  W_branch: torch.Size([8, 128, 256])\n",
      "  bias: torch.Size([1, 2, 128])\n",
      "  W_root.0.weight: torch.Size([128, 96])\n",
      "  W_root.1.weight: torch.Size([128, 256])\n",
      "  W_root.2.weight: torch.Size([128, 256])\n",
      "  W_root.3.weight: torch.Size([128, 256])\n",
      "  W_root.4.weight: torch.Size([128, 128])\n",
      "  W_loop.0.weight: torch.Size([1280, 128])\n",
      "  W_loop.1.weight: torch.Size([128, 1280])\n",
      "\n",
      "Layer 5 parameters:\n",
      "  W_branch: torch.Size([16, 128, 256])\n",
      "  bias: torch.Size([1, 2, 128])\n",
      "  W_root.0.weight: torch.Size([128, 96])\n",
      "  W_root.1.weight: torch.Size([128, 256])\n",
      "  W_root.2.weight: torch.Size([128, 256])\n",
      "  W_root.3.weight: torch.Size([128, 256])\n",
      "  W_root.4.weight: torch.Size([128, 128])\n",
      "  W_root.5.weight: torch.Size([128, 128])\n",
      "  W_loop.0.weight: torch.Size([1280, 128])\n",
      "  W_loop.1.weight: torch.Size([128, 1280])\n",
      "\n",
      "Layer 6 parameters:\n",
      "  W_branch: torch.Size([32, 128, 8192])\n",
      "  W_root.0.weight: torch.Size([3, 96])\n",
      "  W_root.1.weight: torch.Size([3, 256])\n",
      "  W_root.2.weight: torch.Size([3, 256])\n",
      "  W_root.3.weight: torch.Size([3, 256])\n",
      "  W_root.4.weight: torch.Size([3, 128])\n",
      "  W_root.5.weight: torch.Size([3, 128])\n",
      "  W_root.6.weight: torch.Size([3, 128])\n",
      "  W_loop.0.weight: torch.Size([1280, 128])\n",
      "  W_loop.1.weight: torch.Size([3, 1280])\n",
      "[INFO] Loaded 55 matching keys into Generator; skipped 0 mismatched layers.\n",
      "[INFO] Discriminator: loaded checkpoint with strict=True\n",
      "\n",
      "[INFO] Running selective inversion only for IDs: [1091] \n",
      "\n",
      "\n",
      ">>> Processing SELECTED sample ID: 1091\n",
      "\n",
      "[INFO] Using 'cd' + 'feature' (w=0.1) for initial shape selection.\n",
      "[INFO] Saved intermediate reconstruction ‚Üí /kaggle/working/shape_inversion_project_BTP/saved_results/CRN_watercraft_completion_CD/1091_stage0_iter200.txt\n",
      "[INFO] Saved intermediate reconstruction ‚Üí /kaggle/working/shape_inversion_project_BTP/saved_results/CRN_watercraft_completion_CD/1091_stage1_iter400.txt\n",
      "[INFO] Saved intermediate reconstruction ‚Üí /kaggle/working/shape_inversion_project_BTP/saved_results/CRN_watercraft_completion_CD/1091_stage2_iter600.txt\n",
      "[INFO] Saved intermediate reconstruction ‚Üí /kaggle/working/shape_inversion_project_BTP/saved_results/CRN_watercraft_completion_CD/1091_stage3_iter800.txt\n",
      "[DONE] Sample 1091 finished in 26 seconds.\n",
      "\n",
      "<<<<<<<<<<<<<<< ALL SELECTED SAMPLES COMPLETED >>>>>>>>>>>>>>>\n",
      "\n",
      "‚úÖ Finished: watercraft - cd\n",
      "\n",
      "üöÄ Running watercraft with DCD...\n",
      "[INFO] Using device: cuda\n",
      "Current Generator architecture:\n",
      "Number of GCN layers: 7\n",
      "Degrees: [1, 2, 2, 2, 2, 2, 64]\n",
      "Features: [96, 256, 256, 256, 128, 128, 128, 3]\n",
      "\n",
      "Layer 0 parameters:\n",
      "  W_branch: torch.Size([1, 96, 96])\n",
      "  bias: torch.Size([1, 1, 256])\n",
      "  W_root.0.weight: torch.Size([256, 96])\n",
      "  W_loop.0.weight: torch.Size([960, 96])\n",
      "  W_loop.1.weight: torch.Size([256, 960])\n",
      "\n",
      "Layer 1 parameters:\n",
      "  W_branch: torch.Size([1, 256, 512])\n",
      "  bias: torch.Size([1, 2, 256])\n",
      "  W_root.0.weight: torch.Size([256, 96])\n",
      "  W_root.1.weight: torch.Size([256, 256])\n",
      "  W_loop.0.weight: torch.Size([2560, 256])\n",
      "  W_loop.1.weight: torch.Size([256, 2560])\n",
      "\n",
      "Layer 2 parameters:\n",
      "  W_branch: torch.Size([2, 256, 512])\n",
      "  bias: torch.Size([1, 2, 256])\n",
      "  W_root.0.weight: torch.Size([256, 96])\n",
      "  W_root.1.weight: torch.Size([256, 256])\n",
      "  W_root.2.weight: torch.Size([256, 256])\n",
      "  W_loop.0.weight: torch.Size([2560, 256])\n",
      "  W_loop.1.weight: torch.Size([256, 2560])\n",
      "\n",
      "Layer 3 parameters:\n",
      "  W_branch: torch.Size([4, 256, 512])\n",
      "  bias: torch.Size([1, 2, 128])\n",
      "  W_root.0.weight: torch.Size([128, 96])\n",
      "  W_root.1.weight: torch.Size([128, 256])\n",
      "  W_root.2.weight: torch.Size([128, 256])\n",
      "  W_root.3.weight: torch.Size([128, 256])\n",
      "  W_loop.0.weight: torch.Size([2560, 256])\n",
      "  W_loop.1.weight: torch.Size([128, 2560])\n",
      "\n",
      "Layer 4 parameters:\n",
      "  W_branch: torch.Size([8, 128, 256])\n",
      "  bias: torch.Size([1, 2, 128])\n",
      "  W_root.0.weight: torch.Size([128, 96])\n",
      "  W_root.1.weight: torch.Size([128, 256])\n",
      "  W_root.2.weight: torch.Size([128, 256])\n",
      "  W_root.3.weight: torch.Size([128, 256])\n",
      "  W_root.4.weight: torch.Size([128, 128])\n",
      "  W_loop.0.weight: torch.Size([1280, 128])\n",
      "  W_loop.1.weight: torch.Size([128, 1280])\n",
      "\n",
      "Layer 5 parameters:\n",
      "  W_branch: torch.Size([16, 128, 256])\n",
      "  bias: torch.Size([1, 2, 128])\n",
      "  W_root.0.weight: torch.Size([128, 96])\n",
      "  W_root.1.weight: torch.Size([128, 256])\n",
      "  W_root.2.weight: torch.Size([128, 256])\n",
      "  W_root.3.weight: torch.Size([128, 256])\n",
      "  W_root.4.weight: torch.Size([128, 128])\n",
      "  W_root.5.weight: torch.Size([128, 128])\n",
      "  W_loop.0.weight: torch.Size([1280, 128])\n",
      "  W_loop.1.weight: torch.Size([128, 1280])\n",
      "\n",
      "Layer 6 parameters:\n",
      "  W_branch: torch.Size([32, 128, 8192])\n",
      "  W_root.0.weight: torch.Size([3, 96])\n",
      "  W_root.1.weight: torch.Size([3, 256])\n",
      "  W_root.2.weight: torch.Size([3, 256])\n",
      "  W_root.3.weight: torch.Size([3, 256])\n",
      "  W_root.4.weight: torch.Size([3, 128])\n",
      "  W_root.5.weight: torch.Size([3, 128])\n",
      "  W_root.6.weight: torch.Size([3, 128])\n",
      "  W_loop.0.weight: torch.Size([1280, 128])\n",
      "  W_loop.1.weight: torch.Size([3, 1280])\n",
      "[INFO] Loaded 55 matching keys into Generator; skipped 0 mismatched layers.\n",
      "[INFO] Discriminator: loaded checkpoint with strict=True\n",
      "\n",
      "[INFO] Running selective inversion only for IDs: [1091] \n",
      "\n",
      "\n",
      ">>> Processing SELECTED sample ID: 1091\n",
      "\n",
      "[INFO] Using 'dcd' + 'feature' (w=0.1) for initial shape selection.\n",
      "[INFO] Saved intermediate reconstruction ‚Üí /kaggle/working/shape_inversion_project_BTP/saved_results/CRN_watercraft_completion_DCD/1091_stage0_iter200.txt\n",
      "[INFO] Saved intermediate reconstruction ‚Üí /kaggle/working/shape_inversion_project_BTP/saved_results/CRN_watercraft_completion_DCD/1091_stage1_iter400.txt\n",
      "[INFO] Saved intermediate reconstruction ‚Üí /kaggle/working/shape_inversion_project_BTP/saved_results/CRN_watercraft_completion_DCD/1091_stage2_iter600.txt\n",
      "[INFO] Saved intermediate reconstruction ‚Üí /kaggle/working/shape_inversion_project_BTP/saved_results/CRN_watercraft_completion_DCD/1091_stage3_iter800.txt\n",
      "[DONE] Sample 1091 finished in 27 seconds.\n",
      "\n",
      "<<<<<<<<<<<<<<< ALL SELECTED SAMPLES COMPLETED >>>>>>>>>>>>>>>\n",
      "\n",
      "‚úÖ Finished: watercraft - dcd\n",
      "\n",
      "üöÄ Running watercraft with HYPERCD...\n",
      "[INFO] Using device: cuda\n",
      "Current Generator architecture:\n",
      "Number of GCN layers: 7\n",
      "Degrees: [1, 2, 2, 2, 2, 2, 64]\n",
      "Features: [96, 256, 256, 256, 128, 128, 128, 3]\n",
      "\n",
      "Layer 0 parameters:\n",
      "  W_branch: torch.Size([1, 96, 96])\n",
      "  bias: torch.Size([1, 1, 256])\n",
      "  W_root.0.weight: torch.Size([256, 96])\n",
      "  W_loop.0.weight: torch.Size([960, 96])\n",
      "  W_loop.1.weight: torch.Size([256, 960])\n",
      "\n",
      "Layer 1 parameters:\n",
      "  W_branch: torch.Size([1, 256, 512])\n",
      "  bias: torch.Size([1, 2, 256])\n",
      "  W_root.0.weight: torch.Size([256, 96])\n",
      "  W_root.1.weight: torch.Size([256, 256])\n",
      "  W_loop.0.weight: torch.Size([2560, 256])\n",
      "  W_loop.1.weight: torch.Size([256, 2560])\n",
      "\n",
      "Layer 2 parameters:\n",
      "  W_branch: torch.Size([2, 256, 512])\n",
      "  bias: torch.Size([1, 2, 256])\n",
      "  W_root.0.weight: torch.Size([256, 96])\n",
      "  W_root.1.weight: torch.Size([256, 256])\n",
      "  W_root.2.weight: torch.Size([256, 256])\n",
      "  W_loop.0.weight: torch.Size([2560, 256])\n",
      "  W_loop.1.weight: torch.Size([256, 2560])\n",
      "\n",
      "Layer 3 parameters:\n",
      "  W_branch: torch.Size([4, 256, 512])\n",
      "  bias: torch.Size([1, 2, 128])\n",
      "  W_root.0.weight: torch.Size([128, 96])\n",
      "  W_root.1.weight: torch.Size([128, 256])\n",
      "  W_root.2.weight: torch.Size([128, 256])\n",
      "  W_root.3.weight: torch.Size([128, 256])\n",
      "  W_loop.0.weight: torch.Size([2560, 256])\n",
      "  W_loop.1.weight: torch.Size([128, 2560])\n",
      "\n",
      "Layer 4 parameters:\n",
      "  W_branch: torch.Size([8, 128, 256])\n",
      "  bias: torch.Size([1, 2, 128])\n",
      "  W_root.0.weight: torch.Size([128, 96])\n",
      "  W_root.1.weight: torch.Size([128, 256])\n",
      "  W_root.2.weight: torch.Size([128, 256])\n",
      "  W_root.3.weight: torch.Size([128, 256])\n",
      "  W_root.4.weight: torch.Size([128, 128])\n",
      "  W_loop.0.weight: torch.Size([1280, 128])\n",
      "  W_loop.1.weight: torch.Size([128, 1280])\n",
      "\n",
      "Layer 5 parameters:\n",
      "  W_branch: torch.Size([16, 128, 256])\n",
      "  bias: torch.Size([1, 2, 128])\n",
      "  W_root.0.weight: torch.Size([128, 96])\n",
      "  W_root.1.weight: torch.Size([128, 256])\n",
      "  W_root.2.weight: torch.Size([128, 256])\n",
      "  W_root.3.weight: torch.Size([128, 256])\n",
      "  W_root.4.weight: torch.Size([128, 128])\n",
      "  W_root.5.weight: torch.Size([128, 128])\n",
      "  W_loop.0.weight: torch.Size([1280, 128])\n",
      "  W_loop.1.weight: torch.Size([128, 1280])\n",
      "\n",
      "Layer 6 parameters:\n",
      "  W_branch: torch.Size([32, 128, 8192])\n",
      "  W_root.0.weight: torch.Size([3, 96])\n",
      "  W_root.1.weight: torch.Size([3, 256])\n",
      "  W_root.2.weight: torch.Size([3, 256])\n",
      "  W_root.3.weight: torch.Size([3, 256])\n",
      "  W_root.4.weight: torch.Size([3, 128])\n",
      "  W_root.5.weight: torch.Size([3, 128])\n",
      "  W_root.6.weight: torch.Size([3, 128])\n",
      "  W_loop.0.weight: torch.Size([1280, 128])\n",
      "  W_loop.1.weight: torch.Size([3, 1280])\n",
      "[INFO] Loaded 55 matching keys into Generator; skipped 0 mismatched layers.\n",
      "[INFO] Discriminator: loaded checkpoint with strict=True\n",
      "\n",
      "[INFO] Running selective inversion only for IDs: [1091] \n",
      "\n",
      "\n",
      ">>> Processing SELECTED sample ID: 1091\n",
      "\n",
      "[INFO] Using 'hypercd' + 'feature' (w=0.1) for initial shape selection.\n",
      "[INFO] Saved intermediate reconstruction ‚Üí /kaggle/working/shape_inversion_project_BTP/saved_results/CRN_watercraft_completion_HYPERCD/1091_stage0_iter200.txt\n",
      "[INFO] Saved intermediate reconstruction ‚Üí /kaggle/working/shape_inversion_project_BTP/saved_results/CRN_watercraft_completion_HYPERCD/1091_stage1_iter400.txt\n",
      "[INFO] Saved intermediate reconstruction ‚Üí /kaggle/working/shape_inversion_project_BTP/saved_results/CRN_watercraft_completion_HYPERCD/1091_stage2_iter600.txt\n",
      "[INFO] Saved intermediate reconstruction ‚Üí /kaggle/working/shape_inversion_project_BTP/saved_results/CRN_watercraft_completion_HYPERCD/1091_stage3_iter800.txt\n",
      "[DONE] Sample 1091 finished in 26 seconds.\n",
      "\n",
      "<<<<<<<<<<<<<<< ALL SELECTED SAMPLES COMPLETED >>>>>>>>>>>>>>>\n",
      "\n",
      "‚úÖ Finished: watercraft - hypercd\n",
      "\n",
      "üöÄ Running watercraft with INFOCD...\n",
      "[INFO] Using device: cuda\n",
      "Current Generator architecture:\n",
      "Number of GCN layers: 7\n",
      "Degrees: [1, 2, 2, 2, 2, 2, 64]\n",
      "Features: [96, 256, 256, 256, 128, 128, 128, 3]\n",
      "\n",
      "Layer 0 parameters:\n",
      "  W_branch: torch.Size([1, 96, 96])\n",
      "  bias: torch.Size([1, 1, 256])\n",
      "  W_root.0.weight: torch.Size([256, 96])\n",
      "  W_loop.0.weight: torch.Size([960, 96])\n",
      "  W_loop.1.weight: torch.Size([256, 960])\n",
      "\n",
      "Layer 1 parameters:\n",
      "  W_branch: torch.Size([1, 256, 512])\n",
      "  bias: torch.Size([1, 2, 256])\n",
      "  W_root.0.weight: torch.Size([256, 96])\n",
      "  W_root.1.weight: torch.Size([256, 256])\n",
      "  W_loop.0.weight: torch.Size([2560, 256])\n",
      "  W_loop.1.weight: torch.Size([256, 2560])\n",
      "\n",
      "Layer 2 parameters:\n",
      "  W_branch: torch.Size([2, 256, 512])\n",
      "  bias: torch.Size([1, 2, 256])\n",
      "  W_root.0.weight: torch.Size([256, 96])\n",
      "  W_root.1.weight: torch.Size([256, 256])\n",
      "  W_root.2.weight: torch.Size([256, 256])\n",
      "  W_loop.0.weight: torch.Size([2560, 256])\n",
      "  W_loop.1.weight: torch.Size([256, 2560])\n",
      "\n",
      "Layer 3 parameters:\n",
      "  W_branch: torch.Size([4, 256, 512])\n",
      "  bias: torch.Size([1, 2, 128])\n",
      "  W_root.0.weight: torch.Size([128, 96])\n",
      "  W_root.1.weight: torch.Size([128, 256])\n",
      "  W_root.2.weight: torch.Size([128, 256])\n",
      "  W_root.3.weight: torch.Size([128, 256])\n",
      "  W_loop.0.weight: torch.Size([2560, 256])\n",
      "  W_loop.1.weight: torch.Size([128, 2560])\n",
      "\n",
      "Layer 4 parameters:\n",
      "  W_branch: torch.Size([8, 128, 256])\n",
      "  bias: torch.Size([1, 2, 128])\n",
      "  W_root.0.weight: torch.Size([128, 96])\n",
      "  W_root.1.weight: torch.Size([128, 256])\n",
      "  W_root.2.weight: torch.Size([128, 256])\n",
      "  W_root.3.weight: torch.Size([128, 256])\n",
      "  W_root.4.weight: torch.Size([128, 128])\n",
      "  W_loop.0.weight: torch.Size([1280, 128])\n",
      "  W_loop.1.weight: torch.Size([128, 1280])\n",
      "\n",
      "Layer 5 parameters:\n",
      "  W_branch: torch.Size([16, 128, 256])\n",
      "  bias: torch.Size([1, 2, 128])\n",
      "  W_root.0.weight: torch.Size([128, 96])\n",
      "  W_root.1.weight: torch.Size([128, 256])\n",
      "  W_root.2.weight: torch.Size([128, 256])\n",
      "  W_root.3.weight: torch.Size([128, 256])\n",
      "  W_root.4.weight: torch.Size([128, 128])\n",
      "  W_root.5.weight: torch.Size([128, 128])\n",
      "  W_loop.0.weight: torch.Size([1280, 128])\n",
      "  W_loop.1.weight: torch.Size([128, 1280])\n",
      "\n",
      "Layer 6 parameters:\n",
      "  W_branch: torch.Size([32, 128, 8192])\n",
      "  W_root.0.weight: torch.Size([3, 96])\n",
      "  W_root.1.weight: torch.Size([3, 256])\n",
      "  W_root.2.weight: torch.Size([3, 256])\n",
      "  W_root.3.weight: torch.Size([3, 256])\n",
      "  W_root.4.weight: torch.Size([3, 128])\n",
      "  W_root.5.weight: torch.Size([3, 128])\n",
      "  W_root.6.weight: torch.Size([3, 128])\n",
      "  W_loop.0.weight: torch.Size([1280, 128])\n",
      "  W_loop.1.weight: torch.Size([3, 1280])\n",
      "[INFO] Loaded 55 matching keys into Generator; skipped 0 mismatched layers.\n",
      "[INFO] Discriminator: loaded checkpoint with strict=True\n",
      "\n",
      "[INFO] Running selective inversion only for IDs: [1091] \n",
      "\n",
      "\n",
      ">>> Processing SELECTED sample ID: 1091\n",
      "\n",
      "[INFO] Using 'infocd' + 'feature' (w=0.1) for initial shape selection.\n",
      "[INFO] Saved intermediate reconstruction ‚Üí /kaggle/working/shape_inversion_project_BTP/saved_results/CRN_watercraft_completion_INFOCD/1091_stage0_iter200.txt\n",
      "[INFO] Saved intermediate reconstruction ‚Üí /kaggle/working/shape_inversion_project_BTP/saved_results/CRN_watercraft_completion_INFOCD/1091_stage1_iter400.txt\n",
      "[INFO] Saved intermediate reconstruction ‚Üí /kaggle/working/shape_inversion_project_BTP/saved_results/CRN_watercraft_completion_INFOCD/1091_stage2_iter600.txt\n",
      "[INFO] Saved intermediate reconstruction ‚Üí /kaggle/working/shape_inversion_project_BTP/saved_results/CRN_watercraft_completion_INFOCD/1091_stage3_iter800.txt\n",
      "[DONE] Sample 1091 finished in 26 seconds.\n",
      "\n",
      "<<<<<<<<<<<<<<< ALL SELECTED SAMPLES COMPLETED >>>>>>>>>>>>>>>\n",
      "\n",
      "‚úÖ Finished: watercraft - infocd\n",
      "\n",
      "üöÄ Running watercraft with UNIFORMCD...\n",
      "[INFO] Using device: cuda\n",
      "Current Generator architecture:\n",
      "Number of GCN layers: 7\n",
      "Degrees: [1, 2, 2, 2, 2, 2, 64]\n",
      "Features: [96, 256, 256, 256, 128, 128, 128, 3]\n",
      "\n",
      "Layer 0 parameters:\n",
      "  W_branch: torch.Size([1, 96, 96])\n",
      "  bias: torch.Size([1, 1, 256])\n",
      "  W_root.0.weight: torch.Size([256, 96])\n",
      "  W_loop.0.weight: torch.Size([960, 96])\n",
      "  W_loop.1.weight: torch.Size([256, 960])\n",
      "\n",
      "Layer 1 parameters:\n",
      "  W_branch: torch.Size([1, 256, 512])\n",
      "  bias: torch.Size([1, 2, 256])\n",
      "  W_root.0.weight: torch.Size([256, 96])\n",
      "  W_root.1.weight: torch.Size([256, 256])\n",
      "  W_loop.0.weight: torch.Size([2560, 256])\n",
      "  W_loop.1.weight: torch.Size([256, 2560])\n",
      "\n",
      "Layer 2 parameters:\n",
      "  W_branch: torch.Size([2, 256, 512])\n",
      "  bias: torch.Size([1, 2, 256])\n",
      "  W_root.0.weight: torch.Size([256, 96])\n",
      "  W_root.1.weight: torch.Size([256, 256])\n",
      "  W_root.2.weight: torch.Size([256, 256])\n",
      "  W_loop.0.weight: torch.Size([2560, 256])\n",
      "  W_loop.1.weight: torch.Size([256, 2560])\n",
      "\n",
      "Layer 3 parameters:\n",
      "  W_branch: torch.Size([4, 256, 512])\n",
      "  bias: torch.Size([1, 2, 128])\n",
      "  W_root.0.weight: torch.Size([128, 96])\n",
      "  W_root.1.weight: torch.Size([128, 256])\n",
      "  W_root.2.weight: torch.Size([128, 256])\n",
      "  W_root.3.weight: torch.Size([128, 256])\n",
      "  W_loop.0.weight: torch.Size([2560, 256])\n",
      "  W_loop.1.weight: torch.Size([128, 2560])\n",
      "\n",
      "Layer 4 parameters:\n",
      "  W_branch: torch.Size([8, 128, 256])\n",
      "  bias: torch.Size([1, 2, 128])\n",
      "  W_root.0.weight: torch.Size([128, 96])\n",
      "  W_root.1.weight: torch.Size([128, 256])\n",
      "  W_root.2.weight: torch.Size([128, 256])\n",
      "  W_root.3.weight: torch.Size([128, 256])\n",
      "  W_root.4.weight: torch.Size([128, 128])\n",
      "  W_loop.0.weight: torch.Size([1280, 128])\n",
      "  W_loop.1.weight: torch.Size([128, 1280])\n",
      "\n",
      "Layer 5 parameters:\n",
      "  W_branch: torch.Size([16, 128, 256])\n",
      "  bias: torch.Size([1, 2, 128])\n",
      "  W_root.0.weight: torch.Size([128, 96])\n",
      "  W_root.1.weight: torch.Size([128, 256])\n",
      "  W_root.2.weight: torch.Size([128, 256])\n",
      "  W_root.3.weight: torch.Size([128, 256])\n",
      "  W_root.4.weight: torch.Size([128, 128])\n",
      "  W_root.5.weight: torch.Size([128, 128])\n",
      "  W_loop.0.weight: torch.Size([1280, 128])\n",
      "  W_loop.1.weight: torch.Size([128, 1280])\n",
      "\n",
      "Layer 6 parameters:\n",
      "  W_branch: torch.Size([32, 128, 8192])\n",
      "  W_root.0.weight: torch.Size([3, 96])\n",
      "  W_root.1.weight: torch.Size([3, 256])\n",
      "  W_root.2.weight: torch.Size([3, 256])\n",
      "  W_root.3.weight: torch.Size([3, 256])\n",
      "  W_root.4.weight: torch.Size([3, 128])\n",
      "  W_root.5.weight: torch.Size([3, 128])\n",
      "  W_root.6.weight: torch.Size([3, 128])\n",
      "  W_loop.0.weight: torch.Size([1280, 128])\n",
      "  W_loop.1.weight: torch.Size([3, 1280])\n",
      "[INFO] Loaded 55 matching keys into Generator; skipped 0 mismatched layers.\n",
      "[INFO] Discriminator: loaded checkpoint with strict=True\n",
      "\n",
      "[INFO] Running selective inversion only for IDs: [1091] \n",
      "\n",
      "\n",
      ">>> Processing SELECTED sample ID: 1091\n",
      "\n",
      "[INFO] Using 'uniformcd' + 'feature' (w=0.1) for initial shape selection.\n",
      "[INFO] Saved intermediate reconstruction ‚Üí /kaggle/working/shape_inversion_project_BTP/saved_results/CRN_watercraft_completion_UNIFORMCD/1091_stage0_iter200.txt\n",
      "[INFO] Saved intermediate reconstruction ‚Üí /kaggle/working/shape_inversion_project_BTP/saved_results/CRN_watercraft_completion_UNIFORMCD/1091_stage1_iter400.txt\n",
      "[INFO] Saved intermediate reconstruction ‚Üí /kaggle/working/shape_inversion_project_BTP/saved_results/CRN_watercraft_completion_UNIFORMCD/1091_stage2_iter600.txt\n",
      "[INFO] Saved intermediate reconstruction ‚Üí /kaggle/working/shape_inversion_project_BTP/saved_results/CRN_watercraft_completion_UNIFORMCD/1091_stage3_iter800.txt\n",
      "[DONE] Sample 1091 finished in 44 seconds.\n",
      "\n",
      "<<<<<<<<<<<<<<< ALL SELECTED SAMPLES COMPLETED >>>>>>>>>>>>>>>\n",
      "\n",
      "‚úÖ Finished: watercraft - uniformcd\n",
      "\n",
      "‚úÖ All Done.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELL 2: RUN EXPERIMENTS\n",
    "# ===================================================================\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# --- 1. Setup ---\n",
    "if os.path.basename(os.getcwd()) != \"shape_inversion_project_BTP\":\n",
    "    if os.path.exists(\"shape_inversion_project_BTP\"):\n",
    "        os.chdir(\"shape_inversion_project_BTP\")\n",
    "\n",
    "PROJECT_ROOT = os.getcwd()\n",
    "print(f\"üìç Root: {PROJECT_ROOT}\")\n",
    "\n",
    "# --- 2. Configuration ---\n",
    "script_name = \"trainer.py\"  # Using trainer.py as confirmed\n",
    "ckpt_root = os.path.join(PROJECT_ROOT, \"checkpoints\")\n",
    "KAGGLE_INPUT_ROOT = \"/kaggle/input/data-shape-inversion\"\n",
    "ACTUAL_DATA_PATH = os.path.join(KAGGLE_INPUT_ROOT, \"data/our_data\") \n",
    "save_root = os.path.join(PROJECT_ROOT, \"saved_results\")\n",
    "\n",
    "OBJECTS = [\"watercraft\"] \n",
    "LOSSES = [\"cd\", \"dcd\", \"hypercd\", \"infocd\", \"uniformcd\"]\n",
    "SAVE_INTERVAL = 10\n",
    "\n",
    "# --- 3. Environment ---\n",
    "my_env = os.environ.copy()\n",
    "# Add root to path so 'import external...' works\n",
    "my_env[\"PYTHONPATH\"] = f\"{PROJECT_ROOT}:{KAGGLE_INPUT_ROOT}:{my_env.get('PYTHONPATH', '')}\"\n",
    "\n",
    "# --- 4. Execution Loop ---\n",
    "for obj in OBJECTS:\n",
    "    # Target: checkpoints/watercraft/checkpoint.pt\n",
    "    ckpt_path = os.path.join(ckpt_root, obj, \"checkpoint.pt\")\n",
    "    \n",
    "    if not os.path.exists(ckpt_path):\n",
    "        print(f\"‚ö†Ô∏è [SKIPPING] {obj}: Checkpoint not found at {ckpt_path}\")\n",
    "        continue\n",
    "\n",
    "    for loss in LOSSES:\n",
    "        exp_name = f\"CRN_{obj}_completion_{loss.upper()}\"\n",
    "        save_path = os.path.join(save_root, exp_name)\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        cmd = [\n",
    "            \"python\", script_name,\n",
    "            \"--dataset\", \"CRN\",\n",
    "            \"--class_choice\", obj,\n",
    "            \"--inversion_mode\", \"completion\",\n",
    "            \"--loss_func\", loss,\n",
    "            \"--mapping_metric\", loss,\n",
    "            \"--save_inversion_path\", save_path,\n",
    "            \"--ckpt_load\", ckpt_path,\n",
    "            \"--dataset_path\", ACTUAL_DATA_PATH,\n",
    "            \"--save_interval\", str(SAVE_INTERVAL),\n",
    "            \"--visualize\"\n",
    "        ]\n",
    "\n",
    "        print(f\"\\nüöÄ Running {obj} with {loss.upper()}...\")\n",
    "        \n",
    "        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, env=my_env)\n",
    "        \n",
    "        # Print output in real-time\n",
    "        try:\n",
    "            for line in proc.stdout:\n",
    "                print(line, end=\"\")\n",
    "        except Exception as e:\n",
    "            print(f\"Stream error: {e}\")\n",
    "            \n",
    "        proc.wait()\n",
    "        \n",
    "        if proc.returncode != 0:\n",
    "            print(f\"‚ùå Failed: {obj} - {loss}\")\n",
    "        else:\n",
    "            print(f\"‚úÖ Finished: {obj} - {loss}\")\n",
    "\n",
    "print(\"\\n‚úÖ All Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95310af",
   "metadata": {
    "papermill": {
     "duration": 0.003464,
     "end_time": "2026-01-04T17:35:00.224987",
     "exception": false,
     "start_time": "2026-01-04T17:35:00.221523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8647778,
     "sourceId": 13608503,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8648062,
     "sourceId": 13608883,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 327.563457,
   "end_time": "2026-01-04T17:35:00.544690",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-04T17:29:32.981233",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
